# Tool Calls and Questions Summary

## Test File
- **Renamed to:** `e2e/tool-call-selection.test.ts`
- **Tests:** 9 scenarios (3 codebase, 3 diagram, 3 question)
- **Status:** ✅ 9/9 passing

## Questions Being Generated

The questions are dynamically generated by the LLM when `ask_clarifying_question` tool is called. The question text and 4 options come from the tool call arguments.

**Example Tool Call:**
```json
{
  "name": "ask_clarifying_question",
  "arguments": {
    "question": "What type of [system] do you want to create?",
    "question_type": "radio",
    "options": [
      "Option A text",
      "Option B text", 
      "Option C text",
      "Option D text"
    ]
  }
}
```

**Console Output (when question is processed):**
```
❓ QUESTION ASKED:
   Question: "What type of LLM assessor system do you want to create?"
   Options:
     A. Real-time evaluation system
     B. Batch processing system
     C. Hybrid system
     D. Custom solution
   Tool call: ask_clarifying_question
   User message: "make llm assessor"
```

The actual question text varies based on the vague request. The model generates contextually appropriate questions.

## Missing Functionality

### Current Minimal Version Has:
✅ Basic tool selection (works perfectly)
✅ Question generation
✅ Diagram creation  
✅ Codebase tool calls
✅ Basic selection context (just counts: "X nodes, Y edges selected")
✅ Basic unanswered question check (simplified)

### Missing from Full Version:

1. **Rich Selection Context**
   - Missing: Node/edge labels, group details, selected item descriptions
   - Current: Just `"USER SELECTION: X nodes, Y edges selected"`
   - Impact: Can't see what's actually selected to make informed edits

2. **Full Graph State**
   - Missing: Complete graph JSON, all node/edge/group labels
   - Current: Just `isEmpty`, `nodeCount`, `edgeCount`
   - Impact: Agent doesn't know what's already on canvas

3. **Proper Unanswered Question Detection**
   - Missing: Full conversation history scanning for unanswered questions
   - Current: Only checks if last assistant message is a question
   - Impact: Might ask multiple questions or proceed when should wait

4. **Question Sequence Tracking**
   - Missing: Tracking of question sequences, answer tracking
   - Current: Not tracked
   - Impact: Can't manage multi-turn question flows

5. **Rich Agent Context**
   - Missing: Conversation summary, message history, detailed context
   - Current: Minimal 4-field context
   - Impact: Less informed decisions

6. **Error Recovery**
   - Missing: Progressive JSON parsing, multiple recovery attempts
   - Current: Basic try/catch
   - Impact: Tool calls might fail on parsing errors

7. **Multiple Tool Call Handling**
   - Missing: `toolCallsByIndex` Map for handling multiple tool calls
   - Current: Only handles first tool call
   - Impact: Might miss secondary tool calls

8. **Comprehensive Logging**
   - Missing: Debug logs, agent logs, external logging service
   - Current: Basic console.log
   - Impact: Harder to debug production issues

9. **Selection-Based Editing**
   - Missing: Logic to detect edit intent from selection context
   - Current: No edit detection
   - Impact: Can't handle "add X to selected node" properly

10. **Image Processing**
    - Missing: Proper OpenAI image format conversion
    - Current: Basic array handling
    - Impact: Images might not be properly sent to model

## Tool Call Examples

**Codebase Tool Call:**
- Input: `"https://github.com/user/repo"`
- Tool: `codebase`
- Args: `{ "repo_url": "https://github.com/user/repo" }`

**Diagram Tool Call:**
- Input: `"create REST API with Express, PostgreSQL, Redis"`
- Tool: `create_architecture_diagram`
- Args: `{ "requirements_summary": "...", "architecture_type": "microservices" }`

**Question Tool Call:**
- Input: `"make llm assessor"`
- Tool: `ask_clarifying_question`
- Args: `{ "question": "What type of LLM assessor...?", "options": [...] }`



